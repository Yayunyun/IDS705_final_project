{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM0/JwrxlM58O98dl5ZZ2b0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yayunyun/IDS705_final_project/blob/main/training_testing_de_biased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title import module and load data from google drive\n",
        "# connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount = False)\n",
        "# cd to my final project folder\n",
        "%cd /content/drive/Othercomputers/My_MacBook_Pro/final_project/data\n",
        "# move to working folder in colab\n",
        "%cd /content\n",
        "%mkdir final_project\n",
        "%cd final_project\n",
        "\n",
        "# unzip folder from google drive to colab\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images.zip\n",
        "#!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images2.zip\n",
        "#!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images3.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images4.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images5.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images6.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images7.zip\n",
        "#!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images8.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images9.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images10.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images11.zip\n",
        "!unzip /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/images12.zip\n",
        "\n",
        "# copy files from g-drive to colab\n",
        "%cp /content/drive/Othercomputers/My_MacBook_Pro/final_project/data/Data_Entry_2017.csv .\n",
        "# import pacakges\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "from torchvision.io import read_image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "%matplotlib inline\n",
        "print(\"PyTorch Version: \",torch.__version__)\n",
        "print(\"Torchvision Version: \",torchvision.__version__)\n",
        "\n",
        "### OpenMP issues\n",
        "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "%cd /content"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_52KKiqGRCaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data"
      ],
      "metadata": {
        "id": "tGrKSy8-S2x3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_imbalanced_20_80 = pd.read_pickle('/content/drive/Othercomputers/My_MacBook_Pro/final_project/df30_70.pkl')\n",
        "test_df_ = pd.read_pickle('/content/drive/Othercomputers/My_MacBook_Pro/final_project/df_test.pkl')\n"
      ],
      "metadata": {
        "id": "k40iwUrpUwsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ATld_sUCOp6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Model development"
      ],
      "metadata": {
        "id": "y2oRtZXeUwsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters initialization\n"
      ],
      "metadata": {
        "id": "No2nDlVwUwsm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKHwbKetS_8w"
      },
      "outputs": [],
      "source": [
        "# initializae hyperparameter\n",
        "model_name = \"alexnet\"\n",
        "num_classes = 2\n",
        "batch_size = 16\n",
        "num_epochs = 4\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22zAqhKBS_8x"
      },
      "source": [
        "## 2. Create Data Loader for the training and the validation set\n",
        "Returns the image, label and the gender of the person who has taken the X-Ray. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title function to create gender-imablanced data\n",
        "def create_by_ratio(ratio, train_df):\n",
        "\n",
        "  \"\"\"function to create gender-imablanced data\n",
        "  ratio: female:male ratio\n",
        "  train_df: dataframe to use\"\"\"\n",
        "\n",
        "  # make an imbalanced dataset by undersampling female class\n",
        "  train_male = train_df[train_df['Patient Gender'] == 'M']\n",
        "  train_female = train_df[train_df['Patient Gender'] == 'F']\n",
        "  # heart ==1\n",
        "  male_sample_num = train_male[train_male['Sick'] == 1].shape[0]\n",
        "  female_sample_num = np.round(male_sample_num*ratio).astype(int)\n",
        "  female_df1 = train_female[train_female['Sick'] == 1].sample(female_sample_num,  random_state = 1)\n",
        "\n",
        "\n",
        "  df_imbalanced = pd.concat([train_male, female_df1])\n",
        "  df_imbalanced = pd.concat([df_imbalanced, train_female[train_female['Sick'] == 0]])\n",
        "\n",
        "  return df_imbalanced\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "plcK37xoTWtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "LjK7_nkxS_8x"
      },
      "outputs": [],
      "source": [
        "#@title Create dataloader\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, finding, sensitive_attribute, path, transform=None, target_transform=None):\n",
        "        self.img_labels = finding\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "        self.sensitive_attribute = sensitive_attribute\n",
        "        self.path = path\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.path.iloc[idx]\n",
        "        image = Image.open(img_path).convert('RGB') ## change to RGB cuz resnet, densenet only take RGB\n",
        "        label = self.img_labels.iloc[idx]\n",
        "        sensitive_attr = self.sensitive_attribute.iloc[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        sample = {'image': image, 'label': label, 'sensitive_attr':sensitive_attr}\n",
        "        return sample \n",
        "    \n",
        "transform = transforms.Compose([\n",
        "     transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "df_train, df_val = train_test_split(train_df_, test_size=0.2, random_state=1)\n",
        "\n",
        "train_dataset = CustomImageDataset(df_train['Sick'], df_train['gender'], \n",
        "                                df_train['FilePath'], transform=transform)\n",
        "val_dataset = CustomImageDataset(df_val['Sick'], df_val['gender'], \n",
        "                                df_val['FilePath'], transform=transform)\n",
        "df_balanced_test = create_by_ratio(0.5, test_df_)\n",
        "test_dataset = CustomImageDataset(df_balanced_test['Sick'], df_balanced_test['gender'], \n",
        "                                df_balanced_test['FilePath'], transform=transform)\n",
        "\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle = True)\n",
        "\n",
        "val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle = True)\n",
        "\n",
        "\n",
        "combined_data_loader = {\"train\":train_data_loader, \"val\":val_data_loader}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define the arcitecture of the model and the loss function"
      ],
      "metadata": {
        "id": "BXHWv5m6R1h_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "rwxJa8klS_8y"
      },
      "outputs": [],
      "source": [
        "#@title Define fairloss function\n",
        "# SPDX-License-Identifier: GPL-3.0-only\n",
        "# SPDX-FileCopyrightText: 2020 Vincent Lequertier <vi.le@autistici.org>\n",
        "\n",
        "import torch\n",
        "from typing import Callable, Union\n",
        "\n",
        "\n",
        "class FairLoss2(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        loss_fun: torch.nn.Module,\n",
        "        unique_attr: torch.Tensor,\n",
        "        fairness_score: Union[\n",
        "            str, Callable[[torch.Tensor, torch.Tensor], torch.Tensor]],\n",
        "        strength = 0\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Add a fairness measure to the regular loss\n",
        "\n",
        "        fairness_score is applied to input and target for each value of\n",
        "        unique_attr. Then the results are sumed up, divided by the minimum and\n",
        "        added to the regular loss function.\n",
        "\n",
        "\n",
        "        .. math::\n",
        "           loss + \\\\lambda{{\\\\sum_{i=0}^{k} w_i f_i(input, target)} \\\\over \\\\min\\\\limits_{ \\\\forall i\\\\in [0,k[} f_i(input, target)}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`k` is the number of values of ``protected_attr``\n",
        "        - :math:`f` is the ``fairness_score`` function\n",
        "\n",
        "\n",
        "        Args:\n",
        "            loss_fun (torch.nn.Module): A loss function\n",
        "            unique_attr (torch.Tensor): Possible values of a sensitive attribute\n",
        "            fairness_score (Union[str, Callable[[torch.Tensor, torch.Tensor], torch.Tensor]]): A function that takes input and target as arguments and return a score. Or one of 'accuracy', 'fpr', 'tpr', 'tnr', 'fnr', 'ppv', 'npv', 'accuracy'\n",
        "\n",
        "        Examples:\n",
        "            >>> model = Model()\n",
        "            >>> data = torch.randint(0, 5, (100, 5), dtype=torch.float, requires_grad=True)\n",
        "            >>> target = torch.randint(0, 5, (100, 1), dtype=torch.float)\n",
        "            >>> input = model(data)\n",
        "            >>> # The sensitive attribute is the second column\n",
        "            >>> dim = 1\n",
        "            >>> criterion = FairLoss(torch.nn.MSELoss(), data[:, dim].detach().unique(), 'accuracy')\n",
        "            >>> loss = criterion(data[:, dim], y_pred, y_true)\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        self.loss = loss_fun\n",
        "        self.unique_attr = unique_attr\n",
        "        self.fairness_score = (\n",
        "            self.get_fairness_score(fairness_score)\n",
        "            if isinstance(fairness_score, str)\n",
        "            else fairness_score\n",
        "        )\n",
        "        self.strength = strength\n",
        "\n",
        "    def forward(\n",
        "        self, protected_attr: torch.Tensor, input: torch.Tensor, target: torch.Tensor\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Compute the fair loss\n",
        "\n",
        "        Shape:\n",
        "            - protected_attr: :math:`(N,)`\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The fair loss value\n",
        "        \"\"\"\n",
        "        scores = []\n",
        "\n",
        "        for val in self.unique_attr:\n",
        "          fair_input = input[torch.where(protected_attr == val)].reshape(-1,)\n",
        "          fair_target = target[torch.where(protected_attr == val)].reshape(-1,)\n",
        "          scores.append(self.fairness_score(fair_input, fair_target))\n",
        "        scores = torch.FloatTensor(scores)\n",
        "        \n",
        "\n",
        "        # Sum up and divide by the minimum. Then add to the regular loss\n",
        "        target = torch.reshape(target, (-1,1)).float()\n",
        "        loss2 = scores.sum() / (scores.min() + 1e-7)\n",
        "        if torch.isnan(loss2) == True:\n",
        "          loss2 = torch.FloatTensor([0]).cuda()\n",
        "        return_loss = torch.add(self.loss(input, target), self.strength * loss2) \n",
        "        return self.loss(input, target)\n",
        "\n",
        "\n",
        "    def get_fairness_score(\n",
        "        self,\n",
        "        fairness_score: str,\n",
        "    ) -> Callable[[torch.Tensor, torch.Tensor], torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Return one of the fairness scores that are built-in\n",
        "\n",
        "        Args:\n",
        "            fairness_score (str): The fairness score\n",
        "\n",
        "        Returns:\n",
        "            Callable[[torch.Tensor, torch.Tensor], torch.Tensor]: The fairness score function\n",
        "        \"\"\"\n",
        "        if hasattr(self, fairness_score):\n",
        "            return getattr(self, fairness_score)\n",
        "        else:\n",
        "            raise ValueError(\n",
        "                'The fairness score \"{}\" is unavailable'.format(fairness_score)\n",
        "            )\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def fpr(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        False Positive Rate\n",
        "\n",
        "        .. math::\n",
        "           {FPR} = {FP \\\\over FP + TN}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`FP` is the number of False Positive\n",
        "        - :math:`TN` is the number of True Negative\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: False Positive Rate\n",
        "\n",
        "        Examples:\n",
        "            >>> input = np.random.randint(2, size=(10, 1)).astype(\"float\")\n",
        "            >>> input = torch.tensor(input)\n",
        "            >>> target = np.random.randint(2, size=(10, 1)).astype(\"float\")\n",
        "            >>> target = torch.tensor(target)\n",
        "            >>> fpr(input, target)\n",
        "        \"\"\"\n",
        "        fp = sum((input == True) & (target == False))\n",
        "        tn = sum((input == False) & (target == False))\n",
        "        return torch.true_divide(fp, fp + tn)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def tpr(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        True Positive Rate\n",
        "\n",
        "        .. math::\n",
        "           {TPR} = {TP \\\\over TP + FN}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`TP` is the number of True Positive\n",
        "        - :math:`FN` is the number of False Negative\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: True Positive Rate\n",
        "\n",
        "        Examples:\n",
        "            >>> input = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> target = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> tpr(input, target)\n",
        "        \"\"\"\n",
        "        fn = sum((input == False) & (target == True))\n",
        "        tp = sum((input == True) & (target == True))\n",
        "        return torch.true_divide(tp, tp + fn)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def tnr(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        True Negative Rate\n",
        "\n",
        "        .. math::\n",
        "           {TNR} = {TN \\\\over TN + FP}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`TN` is the number of True Negative\n",
        "        - :math:`FP` is the number of False Positive\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: True Negative Rate\n",
        "\n",
        "        Examples:\n",
        "            >>> input = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> target = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> tnr(input, target)\n",
        "        \"\"\"\n",
        "        fp = sum((input == True) & (target == False))\n",
        "        tn = sum((input == False) & (target == False))\n",
        "        return torch.true_divide(tn, tn + fp)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def fnr(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        False Negative Rate\n",
        "\n",
        "        .. math::\n",
        "           {FNR} = {FN \\\\over FN + TP}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`FN` is the number of False Negative\n",
        "        - :math:`TP` is the number of True Positive\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: False Negative Rate\n",
        "\n",
        "        Examples:\n",
        "            >>> input = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> target = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> fnr(input, target)\n",
        "        \"\"\"\n",
        "        input = torch.round(input)\n",
        "        target = torch.round(target)\n",
        "        fn = sum((input == 0) & (target == 1))\n",
        "        tp = sum((input == 1) & (target == 1))\n",
        "        return torch.true_divide(fn, fn + tp)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def ppv(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Positive Predicted Value\n",
        "\n",
        "        .. math::\n",
        "           {PPV} = {TP \\\\over TP + FP}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`TP` is the number of True Positive\n",
        "        - :math:`FP` is the number of False Positive\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Positive Predicted Value\n",
        "\n",
        "        Examples:\n",
        "            >>> input = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> target = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> ppv(input, target)\n",
        "        \"\"\"\n",
        "        tp = sum((input == True) & (target == True))\n",
        "        fp = sum((input == True) & (target == False))\n",
        "        return torch.true_divide(tp, tp + fp)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def npv(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Negative Predicted Value\n",
        "\n",
        "        .. math::\n",
        "           {NPV} = {TN \\\\over TN + FN}\n",
        "\n",
        "        where:\n",
        "\n",
        "        - :math:`TN` is the number of True Negative\n",
        "        - :math:`FN` is the number of False Negative\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Negative Predicted Value\n",
        "\n",
        "        Examples:\n",
        "            >>> input = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> target = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> npv(input, target)\n",
        "        \"\"\"\n",
        "        tn = sum((input == False) & (target == False))\n",
        "        fn = sum((input == False) & (target == True))\n",
        "        return torch.true_divide(tn, tn + fn)\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def accuracy(input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Accuracy\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predicted values\n",
        "            target (torch.Tensor): Ground truth\n",
        "\n",
        "        Shape:\n",
        "            - input: :math:`(N, 1)`\n",
        "            - target: :math:`(N, 1)`\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Accuracy\n",
        "\n",
        "        Examples:\n",
        "            >>> input = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> target = torch.randint(0, 2, (10, 1), dtype=torch.float)\n",
        "            >>> accuracy(input, target)\n",
        "        \"\"\"\n",
        "        input = torch.round(input)\n",
        "        target = torch.round(target)\n",
        "        return torch.true_divide((input == target).sum(), input.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h51k-3umS_8y"
      },
      "outputs": [],
      "source": [
        "#@title Define training code function\n",
        "def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    #params for early stopping\n",
        "    prev_val_loss = 0\n",
        "    stop_patience = 0\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                current_dataloader = dataloaders[phase]\n",
        "                loop = tqdm(current_dataloader)\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                current_dataloader = dataloaders[phase]\n",
        "                loop = tqdm(current_dataloader)\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "        \n",
        "            # Iterate over data.\n",
        "            for idx, data in enumerate(loop):\n",
        "\n",
        "                inputs = data['image'].to(device)\n",
        "                labels = data['label'].to(device)\n",
        "                \n",
        "                sensitive_attr = torch.clone(torch.tensor(data['sensitive_attr']))\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                \n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Get model outputs and calculate loss\n",
        "                    # Special case for inception because in training it has an auxiliary output. In train\n",
        "                    #   mode we calculate the loss by summing the final output and the auxiliary output\n",
        "                    #   but in testing we only consider the final output.\n",
        "                    if is_inception and phase == 'train':\n",
        "                        # From https://discuss.pytorch.org/t/how-to-optimize-inception-model-with-auxiliary-classifiers/7958\n",
        "                        outputs, aux_outputs = model(inputs)\n",
        "                        loss1 = criterion(outputs, labels)\n",
        "                        loss2 = criterion(aux_outputs, labels)\n",
        "                        loss = loss1 + 0.4*loss2\n",
        "                        print('inception', loss)\n",
        "                    else:\n",
        "                        outputs = model(inputs)\n",
        "                        #loss = criterion(outputs, labels)\n",
        "                        loss = criterion(sensitive_attr, outputs, labels) ############# Changed here\n",
        "                        # print(f'batch loss: {loss:.2f}')\n",
        "                    \n",
        "                    # _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                # running_corrects += torch.sum(preds == labels.data)\n",
        "                running_corrects += torch.sum(torch.round(outputs).reshape(-1,1) == labels.reshape(-1,1)).item()\n",
        "                loop.set_description(f\"Epoch[{epoch+1}/{num_epochs}]  - {phase}\")\n",
        "                # loop.set_postfix(loss= 12, acc=12)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "            epoch_acc = running_corrects / len(dataloaders[phase].dataset)\n",
        "\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "            # ## early stopping\n",
        "            # if phase =='val' and epoch_loss > prev_val_loss and prev_val_loss !=0:\n",
        "            #   prev_val_loss = epoch_loss\n",
        "            #   stop_patience += 1\n",
        "            #   if stop_patience == 2:\n",
        "            #     break\n",
        "            # else: \n",
        "            #   prev_val_loss = epoch_loss\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history\n",
        "\n",
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "            "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"alexnet\"\n",
        "# num_classes = df_imbalanced_20_80['Finding Labels'].nunique()\n",
        "num_classes = 2\n",
        "batch_size = 16\n",
        "num_epochs = 4\n",
        "# Flag for feature extracting. When False, we finetune the whole model,\n",
        "#   when True we only update the reshaped layer params\n",
        "feature_extract = False"
      ],
      "metadata": {
        "id": "3W-qUcKSUwsn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PqMddWjCS_8z",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Function for model initialization\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "    input_size = 0\n",
        "\n",
        "    if num_classes == 2:\n",
        "      num_classes = 1 # set loss function to BCEWithLogitsLoss()\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet18\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,1)\n",
        "        model_ft.features[0] = nn.Conv2d(in_channels=1, out_channels=64, kernel_size=3)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"squeezenet\":\n",
        "        \"\"\" Squeezenet\n",
        "        \"\"\"\n",
        "        model_ft = models.squeezenet1_0(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
        "        model_ft.num_classes = num_classes\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"densenet\":\n",
        "        \"\"\" Densenet\n",
        "        \"\"\"\n",
        "        model_ft = models.densenet121(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier.in_features\n",
        "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
        "        input_size = 224\n",
        "\n",
        "    elif model_name == \"inception\":\n",
        "        \"\"\" Inception v3\n",
        "        Be careful, expects (299,299) sized images and has auxiliary output\n",
        "        \"\"\"\n",
        "        model_ft = models.inception_v3(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        # Handle the auxilary net\n",
        "        num_ftrs = model_ft.AuxLogits.fc.in_features\n",
        "        model_ft.AuxLogits.fc = nn.Linear(num_ftrs, num_classes)\n",
        "        # Handle the primary net\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs,num_classes)\n",
        "        input_size = 299\n",
        "\n",
        "    else:\n",
        "        print(\"Invalid model name, exiting...\")\n",
        "        exit()\n",
        "\n",
        "    return model_ft, input_size\n",
        "\n",
        "# Initialize the model for this run\n",
        "model_ft1, input_size = initialize_model('alexnet', num_classes, feature_extract, use_pretrained=True)\n",
        "model_ft1.classifier = nn.Sequential(model_ft1.classifier, nn.Sigmoid())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wI2Grd_XS_8z"
      },
      "outputs": [],
      "source": [
        "# Send the model to GPU\n",
        "model_ft1 = model_ft1.to(device)\n",
        "\n",
        "# Gather the parameters to be optimized/updated in this run. If we are\n",
        "#  finetuning we will be updating all parameters. However, if we are\n",
        "#  doing feature extract method, we will only update the parameters\n",
        "#  that we have just initialized, i.e. the parameters with requires_grad\n",
        "#  is True.\n",
        "params_to_update = model_ft1.parameters()\n",
        "print(\"Params to learn:\")\n",
        "if feature_extract:\n",
        "    params_to_update = []\n",
        "    for name,param in model_ft1.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "            print(\"\\t\",name)\n",
        "else:\n",
        "    for name,param in model_ft1.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "          pass\n",
        "          print(\"\\t\",name)\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loss fxn\n",
        "criterion = FairLoss2(nn.BCELoss(), [1, 0], 'fnr', 0.3) ########change here\n",
        "model_ft1, hist = train_model(model_ft1, combined_data_loader, criterion, optimizer_ft, num_epochs= 15, is_inception=(model_name==\"inception\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtV25fyy7Aet",
        "outputId": "dc666805-ecc2-4f72-aa4f-76f666209dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/840 [00:00<?, ?it/s]<ipython-input-59-45654fcfe056>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  sensitive_attr = torch.clone(torch.tensor(data['sensitive_attr']))\n",
            "Epoch[1/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 267427.5737 Acc: 0.5796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[1/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 290834.6145 Acc: 0.6101\n",
            "\n",
            "Epoch 2/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[2/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 379180.4837 Acc: 0.6152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[2/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 448260.8283 Acc: 0.6473\n",
            "\n",
            "Epoch 3/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[3/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 362698.4832 Acc: 0.6330\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[3/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 508838.8679 Acc: 0.6446\n",
            "\n",
            "Epoch 4/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[4/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 427837.7233 Acc: 0.6505\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[4/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 483691.3051 Acc: 0.6277\n",
            "\n",
            "Epoch 5/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[5/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 374734.2558 Acc: 0.6612\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[5/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 282518.2842 Acc: 0.6432\n",
            "\n",
            "Epoch 6/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[6/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 425950.3174 Acc: 0.6725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[6/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 549941.7225 Acc: 0.6786\n",
            "\n",
            "Epoch 7/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[7/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 453857.5117 Acc: 0.6766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[7/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 535533.9278 Acc: 0.6738\n",
            "\n",
            "Epoch 8/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[8/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 432287.9113 Acc: 0.6782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[8/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 290205.3054 Acc: 0.6378\n",
            "\n",
            "Epoch 9/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[9/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 442872.5937 Acc: 0.6843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[9/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 354893.4855 Acc: 0.6747\n",
            "\n",
            "Epoch 10/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[10/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 460144.4380 Acc: 0.6890\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[10/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 421815.2850 Acc: 0.6655\n",
            "\n",
            "Epoch 11/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[11/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 502889.2675 Acc: 0.6937\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[11/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 377603.2051 Acc: 0.6833\n",
            "\n",
            "Epoch 12/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[12/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 520384.1554 Acc: 0.7009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[12/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 572795.8405 Acc: 0.6625\n",
            "\n",
            "Epoch 13/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[13/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 494883.5310 Acc: 0.7015\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[13/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 450465.9864 Acc: 0.6801\n",
            "\n",
            "Epoch 14/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[14/15]  - train: 100%|██████████| 840/840 [04:36<00:00,  3.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 391858.4413 Acc: 0.7117\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[14/15]  - val: 100%|██████████| 210/210 [01:07<00:00,  3.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 469190.4700 Acc: 0.6747\n",
            "\n",
            "Epoch 15/15\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[15/15]  - train: 100%|██████████| 840/840 [04:37<00:00,  3.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 460120.2985 Acc: 0.7168\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch[15/15]  - val: 100%|██████████| 210/210 [01:08<00:00,  3.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 470936.5183 Acc: 0.6747\n",
            "\n",
            "Training complete in 86m 20s\n",
            "Best val Acc: 0.683333\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # save model\n",
        "torch.save(model_ft1.state_dict(), \\\n",
        "           '/content/drive/Othercomputers/My_MacBook_Pro/final_project/torch_dbmodel_8020_03.pth')\n",
        "\n"
      ],
      "metadata": {
        "id": "5SVNL3dQC_0f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predictions"
      ],
      "metadata": {
        "id": "yuWa_yhbR66Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title function to get different metrics on the test set\n",
        "def get_metricss(logits, ratio, df_balanced_test):\n",
        "  \"\"\"function to get metrics on the test set\n",
        "  logits: output from the model\n",
        "  ratio: label for the gender-imablance test set\n",
        "  df_balanced_test: test data\"\"\"\n",
        "\n",
        "  predict_classes = np.round(logits) # use 0.5 as cut-off value\n",
        "  predict_classes = predict_classes\n",
        "  df_balanced_test['predict_classes'] = predict_classes\n",
        "\n",
        "  # evaluate overall \n",
        "  precision_ = precision_score(np.array(df_balanced_test['Sick'], dtype='int64').reshape(-1,), predict_classes)\n",
        "  accuracy_ = accuracy_score(np.array(df_balanced_test['Sick'], dtype='int64').reshape(-1,), predict_classes)\n",
        "  recall_ = recall_score(np.array(df_balanced_test['Sick'], dtype='int64').reshape(-1,), predict_classes)\n",
        "  f1_ = f1_score(np.array(df_balanced_test['Sick'], dtype='int64').reshape(-1,), predict_classes)\n",
        "  fpr = len(df_balanced_test[(df_balanced_test['predict_classes'] == 1)& (df_balanced_test['Sick'] == 0)])/len(df_balanced_test[df_balanced_test['Sick'] == 0])\n",
        "  fnr = len(df_balanced_test[(df_balanced_test['predict_classes'] == 0)& (df_balanced_test['Sick'] == 1)])/len(df_balanced_test[df_balanced_test['Sick'] == 1])\n",
        "\n",
        "\n",
        "\n",
        "  # evaluate preformance for male and female\n",
        "  df_balanced_test['predict_classes'] = predict_classes\n",
        "  male_test = df_balanced_test[df_balanced_test['Patient Gender'] == 'M']\n",
        "  female_test = df_balanced_test[df_balanced_test['Patient Gender'] == 'F']\n",
        "\n",
        "  male_precision = precision_score(np.array(male_test['Sick'], dtype='int64').reshape(-1,), male_test['predict_classes'])\n",
        "  female_precision = precision_score(np.array(female_test['Sick'], dtype='int64').reshape(-1,), female_test['predict_classes'])\n",
        "\n",
        "  male_accuracy = accuracy_score(np.array(male_test['Sick'], dtype='int64').reshape(-1,), male_test['predict_classes'])\n",
        "  female_accuracy = accuracy_score(np.array(female_test['Sick'], dtype='int64').reshape(-1,), female_test['predict_classes'])\n",
        "\n",
        "  male_recall = recall_score(np.array(male_test['Sick'], dtype='int64').reshape(-1,), male_test['predict_classes'])\n",
        "  female_recall = recall_score(np.array(female_test['Sick'], dtype='int64').reshape(-1,), female_test['predict_classes'])\n",
        "\n",
        "  male_f1 = f1_score(np.array(male_test['Sick'], dtype='int64').reshape(-1,), male_test['predict_classes'])\n",
        "  female_f1 = f1_score(np.array(female_test['Sick'], dtype='int64').reshape(-1,), female_test['predict_classes'])\n",
        "\n",
        "  male_fpr = len(male_test[(male_test['predict_classes'] == 1)& (male_test['Sick'] == 0)])/len(male_test[male_test['Sick'] == 0])\n",
        "  male_fnr = len(male_test[(male_test['predict_classes'] == 0)& (male_test['Sick'] == 1)])/len(male_test[male_test['Sick'] ==1])\n",
        "\n",
        "\n",
        "  female_fpr = len(female_test[(female_test['predict_classes'] == 1)& (female_test['Sick'] == 0)])/len(female_test[female_test['Sick'] == 0])\n",
        "  female_fnr = len(female_test[(female_test['predict_classes'] == 0)& (female_test['Sick'] == 1)])/len(female_test[female_test['Sick'] ==1])\n",
        "\n",
        "  fairness_metric = (((len(female_test)/len(df_balanced_test))*female_fnr) + ((len(male_test)/len(df_balanced_test))* male_fnr))/min(female_fnr, male_fnr)\n",
        "  results = [ratio, precision_, male_precision, female_precision,\\\n",
        "                           accuracy_, male_accuracy, female_accuracy, \\\n",
        "                           recall_, male_recall, female_recall, \\\n",
        "                           f1_, male_f1, female_f1, \\\n",
        "                          fpr, male_fpr, female_fpr, \\\n",
        "                          fnr, male_fnr, female_fnr, fairness_metric]\n",
        "  return results                          "
      ],
      "metadata": {
        "id": "cXsnxyVGRgdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# predict on 50 50 test set\n",
        "test_data_loader = DataLoader(test_dataset, batch_size= 64, shuffle = False, num_workers = 10)\n",
        "x = np.array([])\n",
        "for data in test_data_loader:\n",
        "  inputs =  data['image'].cuda()\n",
        "  outputs = model_ft1(inputs).detach().cpu().numpy().reshape(-1,)\n",
        "  x = np.concatenate((x, outputs), axis = 0)\n",
        "results_70_1 = get_metricss(x, 'M/F db model train:80/20 test: 50/50', df_balanced_test)\n",
        "\n",
        "\n",
        "# predict on 70 30 test set\n",
        "df_balanced_test1 = create_by_ratio(30/70, test_df_)\n",
        "test_dataset_3070 = CustomImageDataset(df_balanced_test1['Sick'], df_balanced_test1['gender'], \n",
        "                                df_balanced_test1['FilePath'], transform=transform)\n",
        "test_data_loader1 = DataLoader(test_dataset_3070, batch_size= 64, shuffle = False, num_workers = 10)\n",
        "x2 = np.array([])\n",
        "for data in test_data_loader1:\n",
        "  inputs =  data['image'].cuda()\n",
        "  outputs = model_ft1(inputs).detach().cpu().numpy().reshape(-1,)\n",
        "  x2 = np.concatenate((x2, outputs), axis = 0)\n",
        "\n",
        "results_70_2 = get_metricss(x2, 'M/F db model train:80/20 test: 70/30', df_balanced_test1)\n",
        "\n",
        "# predict on 90 10 test set\n",
        "df_balanced_test2 = create_by_ratio(10/90, test_df_)\n",
        "test_dataset_1090 = CustomImageDataset(df_balanced_test2['Sick'], df_balanced_test2['gender'], \n",
        "                                df_balanced_test2['FilePath'], transform=transform)\n",
        "test_data_loader2 = DataLoader(test_dataset_1090, batch_size= 64, shuffle = False, num_workers = 10)\n",
        "x3 = np.array([])\n",
        "for data in test_data_loader2:\n",
        "  inputs =  data['image'].cuda()\n",
        "  outputs = model_ft1(inputs).detach().cpu().numpy().reshape(-1,)\n",
        "  x3 = np.concatenate((x3, outputs), axis = 0)\n",
        "\n",
        "results_70_3 = get_metricss(x3, 'M/F db model train:80/20 test: 90/10', df_balanced_test2)"
      ],
      "metadata": {
        "id": "3GHgMj5HYVQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(columns = ['male/female', 'precision', 'male_precision', 'female_precision',\\\n",
        "                                    'accuracy', 'male_accuracy', 'female_accuracy', \\\n",
        "                                    'recall', 'male_recall', 'female_recall',\\\n",
        "                                    'f1', 'male_f1', 'female_f1', 'fpr', 'male_fpr', 'female_fpr', \\\n",
        "                                     'fnr', 'male_fnr', 'female_fnr', 'fairness_metric'])\n",
        "results_df.loc[0] = results_70_1\n",
        "results_df.loc[1] = results_70_2\n",
        "results_df.loc[2] = results_70_3"
      ],
      "metadata": {
        "id": "tMe8itiHRgam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "UhmGuC21RgYa",
        "outputId": "350eb183-0b9a-496c-9d3b-e8d342e5aa69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            male/female  precision  male_precision  \\\n",
              "0  M/F db model train:80/20 test: 50/50   0.671141        0.708648   \n",
              "1  M/F db model train:80/20 test: 70/30   0.661290        0.708648   \n",
              "2  M/F db model train:80/20 test: 90/10   0.609562        0.708648   \n",
              "\n",
              "   female_precision  accuracy  male_accuracy  female_accuracy    recall  \\\n",
              "0          0.596315  0.665900       0.667925         0.662743  0.581114   \n",
              "1          0.557798  0.669019       0.667925         0.670831  0.583630   \n",
              "2          0.234921  0.685370       0.667925         0.725086  0.600000   \n",
              "\n",
              "   male_recall  female_recall        f1   male_f1  female_f1       fpr  \\\n",
              "0     0.612927       0.517442  0.622891  0.657321   0.554086  0.257443   \n",
              "1     0.612927       0.515254  0.620038  0.657321   0.535683  0.257443   \n",
              "2     0.612927       0.483660  0.604743  0.657321   0.316239  0.257443   \n",
              "\n",
              "   male_fpr  female_fpr       fnr  male_fnr  female_fnr  fairness_metric  \n",
              "0  0.272584    0.238378  0.418886  0.387073    0.482558         1.096371  \n",
              "1  0.272584    0.238378  0.416370  0.387073    0.484746         1.095034  \n",
              "2  0.272584    0.238378  0.400000  0.387073    0.516340         1.101921  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9268ebdc-9134-46ce-a075-b61405361512\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male/female</th>\n",
              "      <th>precision</th>\n",
              "      <th>male_precision</th>\n",
              "      <th>female_precision</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>male_accuracy</th>\n",
              "      <th>female_accuracy</th>\n",
              "      <th>recall</th>\n",
              "      <th>male_recall</th>\n",
              "      <th>female_recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>male_f1</th>\n",
              "      <th>female_f1</th>\n",
              "      <th>fpr</th>\n",
              "      <th>male_fpr</th>\n",
              "      <th>female_fpr</th>\n",
              "      <th>fnr</th>\n",
              "      <th>male_fnr</th>\n",
              "      <th>female_fnr</th>\n",
              "      <th>fairness_metric</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M/F db model train:80/20 test: 50/50</td>\n",
              "      <td>0.671141</td>\n",
              "      <td>0.708648</td>\n",
              "      <td>0.596315</td>\n",
              "      <td>0.665900</td>\n",
              "      <td>0.667925</td>\n",
              "      <td>0.662743</td>\n",
              "      <td>0.581114</td>\n",
              "      <td>0.612927</td>\n",
              "      <td>0.517442</td>\n",
              "      <td>0.622891</td>\n",
              "      <td>0.657321</td>\n",
              "      <td>0.554086</td>\n",
              "      <td>0.257443</td>\n",
              "      <td>0.272584</td>\n",
              "      <td>0.238378</td>\n",
              "      <td>0.418886</td>\n",
              "      <td>0.387073</td>\n",
              "      <td>0.482558</td>\n",
              "      <td>1.096371</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M/F db model train:80/20 test: 70/30</td>\n",
              "      <td>0.661290</td>\n",
              "      <td>0.708648</td>\n",
              "      <td>0.557798</td>\n",
              "      <td>0.669019</td>\n",
              "      <td>0.667925</td>\n",
              "      <td>0.670831</td>\n",
              "      <td>0.583630</td>\n",
              "      <td>0.612927</td>\n",
              "      <td>0.515254</td>\n",
              "      <td>0.620038</td>\n",
              "      <td>0.657321</td>\n",
              "      <td>0.535683</td>\n",
              "      <td>0.257443</td>\n",
              "      <td>0.272584</td>\n",
              "      <td>0.238378</td>\n",
              "      <td>0.416370</td>\n",
              "      <td>0.387073</td>\n",
              "      <td>0.484746</td>\n",
              "      <td>1.095034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M/F db model train:80/20 test: 90/10</td>\n",
              "      <td>0.609562</td>\n",
              "      <td>0.708648</td>\n",
              "      <td>0.234921</td>\n",
              "      <td>0.685370</td>\n",
              "      <td>0.667925</td>\n",
              "      <td>0.725086</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.612927</td>\n",
              "      <td>0.483660</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>0.657321</td>\n",
              "      <td>0.316239</td>\n",
              "      <td>0.257443</td>\n",
              "      <td>0.272584</td>\n",
              "      <td>0.238378</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.387073</td>\n",
              "      <td>0.516340</td>\n",
              "      <td>1.101921</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9268ebdc-9134-46ce-a075-b61405361512')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9268ebdc-9134-46ce-a075-b61405361512 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9268ebdc-9134-46ce-a075-b61405361512');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df.to_csv('/content/drive/Othercomputers/My_MacBook_Pro/final_project/result_db8020.csv')"
      ],
      "metadata": {
        "id": "ux-0F3hoRgUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJsI1fZ6RgSC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}